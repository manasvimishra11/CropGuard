{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCOC86DYRVq6",
        "outputId": "03b03c35-ece1-4b5a-c29d-abf4193729f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsYCd5lnRbGn"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/drive/MyDrive/PlantVillage/PlantVillage/Potato'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09OfoC2rRd7x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR6wmMj_Rf5P"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import tensorflow.keras as keras\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WbhLuykRh8h",
        "outputId": "3c8c53a6-0388-4b5c-b4b9-a429ff185ade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split into training and validation sets.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the source directory containing your dataset\n",
        "source_dir = \"/content/drive/MyDrive/PlantVillage/PlantVillage/Potato\"\n",
        "\n",
        "# Define the destination directories for training and validation data\n",
        "train_dir = \"potato/train\"\n",
        "valid_dir = \"potato/valid\"\n",
        "\n",
        "# Create the destination directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(valid_dir, exist_ok=True)\n",
        "\n",
        "# Get a list of class folders in the source directory\n",
        "class_folders = os.listdir(source_dir)\n",
        "\n",
        "# Define the ratio of data to put in the validation set (e.g., 20%)\n",
        "validation_ratio = 0.2\n",
        "\n",
        "# Loop through each class folder and split the data\n",
        "for class_folder in class_folders:\n",
        "    class_path = os.path.join(source_dir, class_folder)\n",
        "    if os.path.isdir(class_path):\n",
        "        images = os.listdir(class_path)\n",
        "        # Split the images into training and validation sets\n",
        "        train_images, valid_images = train_test_split(images, test_size=validation_ratio, random_state=42)\n",
        "\n",
        "        # Create destination directories for this class in the training and validation sets\n",
        "        train_class_dir = os.path.join(train_dir, class_folder)\n",
        "        valid_class_dir = os.path.join(valid_dir, class_folder)\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(valid_class_dir, exist_ok=True)\n",
        "\n",
        "        # Copy training images\n",
        "        for image in train_images:\n",
        "            source_image_path = os.path.join(class_path, image)\n",
        "            dest_image_path = os.path.join(train_class_dir, image)\n",
        "            shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "        # Copy validation images\n",
        "        for image in valid_images:\n",
        "            source_image_path = os.path.join(class_path, image)\n",
        "            dest_image_path = os.path.join(valid_class_dir, image)\n",
        "            shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "print(\"Dataset split into training and validation sets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yX2qwuPRk4N",
        "outputId": "cd3e489f-0fae-4017-fa12-ffa6ce027d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in the training directory: 1721\n",
            "Number of files in the validation directory: 431\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DIR = \"potato/train\"\n",
        "VALID_DIR = \"potato/valid\"\n",
        "def count_files_in_directory(directory):\n",
        "    total_files = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        total_files += len(files)\n",
        "    return total_files\n",
        "\n",
        "num_train_files = count_files_in_directory(TRAIN_DIR)\n",
        "num_valid_files = count_files_in_directory(VALID_DIR)\n",
        "\n",
        "print(\"Number of files in the training directory:\", num_train_files)\n",
        "print(\"Number of files in the validation directory:\", num_valid_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwZitKsXRoDW",
        "outputId": "53d9eb51-a5f9-4e9e-e91e-fe3ef108dc1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes in the training directory: 3\n",
            "Class names in the training directory:\n",
            "Potato___healthy\n",
            "Potato___Late_blight\n",
            "Potato___Early_blight\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DIR = \"potato/train\"\n",
        "\n",
        "def get_classes_and_count(directory):\n",
        "    classes = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
        "    return classes, len(classes)\n",
        "\n",
        "class_names, CLASS_NUMS = get_classes_and_count(TRAIN_DIR)\n",
        "\n",
        "print(\"Number of classes in the training directory:\", CLASS_NUMS)\n",
        "print(\"Class names in the training directory:\")\n",
        "for class_name in class_names:\n",
        "    print(class_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "# Define directories and constants\n",
        "source_dir = \"/content/drive/MyDrive/PlantVillage/PlantVillage/Potato\"\n",
        "train_dir = \"potato/train\"\n",
        "valid_dir = \"potato/valid\"\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "numEPOCHS = 7  # You can increase the number of epochs\n",
        "\n",
        "# Data Augmentation\n",
        "training_aug = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "testing_aug = ImageDataGenerator(rescale=1./255.0)\n",
        "\n",
        "# Load and preprocess data\n",
        "training_data = training_aug.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "testing_data = testing_aug.flow_from_directory(\n",
        "    valid_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Define and compile the model\n",
        "base_model = InceptionV3(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(CLASS_NUMS, activation='softmax')\n",
        "])\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "def lr_scheduler(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.0001\n",
        "\n",
        "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Training with early stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    training_data,\n",
        "    validation_data=testing_data,\n",
        "    epochs=numEPOCHS,\n",
        "    steps_per_epoch=len(training_data),\n",
        "    validation_steps=len(testing_data),\n",
        "    callbacks=[early_stopping, lr_schedule]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGeE_cfMQjxY",
        "outputId": "3cf41544-fdc0-4a5b-aa7b-ed03b9742a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1721 images belonging to 3 classes.\n",
            "Found 431 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n",
            "Epoch 1/7\n",
            "54/54 [==============================] - 72s 626ms/step - loss: 0.4691 - accuracy: 0.8762 - val_loss: 47.5694 - val_accuracy: 0.4640 - lr: 0.0010\n",
            "Epoch 2/7\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.1699 - accuracy: 0.9436 - val_loss: 19.1406 - val_accuracy: 0.4733 - lr: 0.0010\n",
            "Epoch 3/7\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.1212 - accuracy: 0.9593 - val_loss: 2.6460 - val_accuracy: 0.6427 - lr: 0.0010\n",
            "Epoch 4/7\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0766 - accuracy: 0.9744 - val_loss: 1.0236 - val_accuracy: 0.7819 - lr: 0.0010\n",
            "Epoch 5/7\n",
            "54/54 [==============================] - 28s 521ms/step - loss: 0.0531 - accuracy: 0.9814 - val_loss: 0.0423 - val_accuracy: 0.9907 - lr: 0.0010\n",
            "Epoch 6/7\n",
            "54/54 [==============================] - 28s 521ms/step - loss: 0.0519 - accuracy: 0.9831 - val_loss: 0.2722 - val_accuracy: 0.9234 - lr: 0.0010\n",
            "Epoch 7/7\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 0.1917 - val_accuracy: 0.9513 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHHqlDAURwUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57613fa-7bfe-480c-9af6-3c5e8e9334a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save(\"potato_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdrQNaQDGknH"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import warnings\n",
        "\n",
        "#lodaing the trained model\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "model = keras.models.load_model('potato_model.h5')\n",
        "\n",
        "#converting model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "#saving tflite model\n",
        "with open('potato.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "#creating interpreter for our model\n",
        "interpreter = tf.lite.Interpreter(model_path='potato.tflite')\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OQOmhyHGofO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b28a9f9d-4b73-45c6-da94-4d2592649160"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_16236f83-8d6d-4de0-b1dd-fa8b5f7f4e92\", \"potato_model.h5\", 275160464)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"potato_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUIAFaHKGqae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6046c5c6-6691-481c-81b7-0b609e318bdc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c7e7125e-2642-4ef1-a8b7-56b89b33ccc3\", \"potato.tflite\", 91339472)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"potato.tflite\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}