{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bzChom-4HXf",
        "outputId": "b060703e-09eb-4ace-97d0-2ab5f929a5ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79s-Fd4Y6j8f"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/drive/MyDrive/PlantVillage/PlantVillage/Tomato'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oorjqGtO5jTl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePjQkPiv5mp2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import tensorflow.keras as keras\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j-2wTxc5p_r",
        "outputId": "149bfc6b-3bca-4883-e30a-541f08637603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split into training and validation sets.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the source directory containing your dataset\n",
        "source_dir = \"/content/drive/MyDrive/PlantVillage/Tomato\"\n",
        "\n",
        "# Define the destination directories for training and validation data\n",
        "train_dir = \"tomato/train\"\n",
        "valid_dir = \"tomato/valid\"\n",
        "\n",
        "# Create the destination directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(valid_dir, exist_ok=True)\n",
        "\n",
        "# Get a list of class folders in the source directory\n",
        "class_folders = os.listdir(source_dir)\n",
        "\n",
        "# Define the ratio of data to put in the validation set (e.g., 20%)\n",
        "validation_ratio = 0.2\n",
        "\n",
        "# Loop through each class folder and split the data\n",
        "for class_folder in class_folders:\n",
        "    class_path = os.path.join(source_dir, class_folder)\n",
        "    if os.path.isdir(class_path):\n",
        "        images = os.listdir(class_path)\n",
        "        # Split the images into training and validation sets\n",
        "        train_images, valid_images = train_test_split(images, test_size=validation_ratio, random_state=42)\n",
        "\n",
        "        # Create destination directories for this class in the training and validation sets\n",
        "        train_class_dir = os.path.join(train_dir, class_folder)\n",
        "        valid_class_dir = os.path.join(valid_dir, class_folder)\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(valid_class_dir, exist_ok=True)\n",
        "\n",
        "        # Copy training images\n",
        "        for image in train_images:\n",
        "            source_image_path = os.path.join(class_path, image)\n",
        "            dest_image_path = os.path.join(train_class_dir, image)\n",
        "            shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "        # Copy validation images\n",
        "        for image in valid_images:\n",
        "            source_image_path = os.path.join(class_path, image)\n",
        "            dest_image_path = os.path.join(valid_class_dir, image)\n",
        "            shutil.copy(source_image_path, dest_image_path)\n",
        "\n",
        "print(\"Dataset split into training and validation sets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xsT6ZuC5tDq",
        "outputId": "75e3ca7f-7627-42c6-e5e2-5cd76ee021da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in the training directory: 12813\n",
            "Number of files in the validation directory: 3209\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DIR = \"tomato/train\"\n",
        "VALID_DIR = \"tomato/valid\"\n",
        "def count_files_in_directory(directory):\n",
        "    total_files = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        total_files += len(files)\n",
        "    return total_files\n",
        "\n",
        "num_train_files = count_files_in_directory(TRAIN_DIR)\n",
        "num_valid_files = count_files_in_directory(VALID_DIR)\n",
        "\n",
        "print(\"Number of files in the training directory:\", num_train_files)\n",
        "print(\"Number of files in the validation directory:\", num_valid_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdnCPI0B5vgm",
        "outputId": "0795a644-74ca-4a0a-9c13-cee885764f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes in the training directory: 10\n",
            "Class names in the training directory:\n",
            "Tomato_healthy\n",
            "Tomato_Bacterial_spot\n",
            "Tomato_Early_blight\n",
            "Tomato_Septoria_leaf_spot\n",
            "Tomato_Spider_mites_Two_spotted_spider_mite\n",
            "Tomato_Leaf_Mold\n",
            "Tomato_Late_blight\n",
            "Tomato__Tomato_mosaic_virus\n",
            "Tomato__Target_Spot\n",
            "Tomato__Tomato_YellowLeaf__Curl_Virus\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DIR = \"tomato/train\"\n",
        "\n",
        "def get_classes_and_count(directory):\n",
        "    classes = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
        "    return classes, len(classes)\n",
        "\n",
        "class_names, CLASS_NUMS = get_classes_and_count(TRAIN_DIR)\n",
        "\n",
        "print(\"Number of classes in the training directory:\", CLASS_NUMS)\n",
        "print(\"Class names in the training directory:\")\n",
        "for class_name in class_names:\n",
        "    print(class_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpt7ySGo5x-j",
        "outputId": "7546b856-b776-4819-92b9-90dfc2739a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12812 images belonging to 10 classes.\n",
            "Found 3209 images belonging to 10 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "Epoch 1/7\n",
            "401/401 [==============================] - 278s 581ms/step - loss: 0.7595 - accuracy: 0.7651 - val_loss: 5.7559 - val_accuracy: 0.1328\n",
            "Epoch 2/7\n",
            "401/401 [==============================] - 226s 564ms/step - loss: 0.3648 - accuracy: 0.8809 - val_loss: 5.1883 - val_accuracy: 0.1016\n",
            "Epoch 3/7\n",
            "401/401 [==============================] - 240s 598ms/step - loss: 0.2626 - accuracy: 0.9170 - val_loss: 4.8861 - val_accuracy: 0.3970\n",
            "Epoch 4/7\n",
            "401/401 [==============================] - 227s 565ms/step - loss: 0.2160 - accuracy: 0.9294 - val_loss: 0.9051 - val_accuracy: 0.7435\n",
            "Epoch 5/7\n",
            "401/401 [==============================] - 238s 594ms/step - loss: 0.1598 - accuracy: 0.9485 - val_loss: 2.0812 - val_accuracy: 0.6731\n",
            "Epoch 6/7\n",
            "401/401 [==============================] - 229s 571ms/step - loss: 0.1678 - accuracy: 0.9469 - val_loss: 0.4710 - val_accuracy: 0.8520\n",
            "Epoch 7/7\n",
            "401/401 [==============================] - 236s 589ms/step - loss: 0.1423 - accuracy: 0.9559 - val_loss: 0.9465 - val_accuracy: 0.8099\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50  # Example pre-trained model\n",
        "\n",
        "# Define directories and constants\n",
        "source_dir = \"/content/drive/MyDrive/PlantVillage/PlantVillage/Tomato\"\n",
        "train_dir = \"tomato/train\"\n",
        "valid_dir = \"tomato/valid\"\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "numEPOCHS = 7\n",
        "\n",
        "# Data Augmentation\n",
        "training_aug = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "testing_aug = ImageDataGenerator(rescale=1./255.0)\n",
        "\n",
        "# Load and preprocess data\n",
        "training_data = training_aug.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical')\n",
        "\n",
        "testing_data = testing_aug.flow_from_directory(\n",
        "    valid_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Define and compile the model\n",
        "base_model = ResNet50(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(CLASS_NUMS, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Training with early stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    training_data,\n",
        "    validation_data=testing_data,\n",
        "    epochs=numEPOCHS,\n",
        "    steps_per_epoch=len(training_data),\n",
        "    validation_steps=len(testing_data),\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZLyQK4cGGBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347f27f3-ad2f-4c12-d2c4-5011d969113c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12812 images belonging to 10 classes.\n",
            "Found 3209 images belonging to 10 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n",
            "Epoch 1/7\n",
            "401/401 [==============================] - 247s 525ms/step - loss: 0.6716 - accuracy: 0.7922 - val_loss: 0.4302 - val_accuracy: 0.8803 - lr: 0.0010\n",
            "Epoch 2/7\n",
            "401/401 [==============================] - 215s 537ms/step - loss: 0.2737 - accuracy: 0.9132 - val_loss: 0.7230 - val_accuracy: 0.8535 - lr: 0.0010\n",
            "Epoch 3/7\n",
            "401/401 [==============================] - 209s 519ms/step - loss: 0.2182 - accuracy: 0.9330 - val_loss: 0.2356 - val_accuracy: 0.9392 - lr: 0.0010\n",
            "Epoch 4/7\n",
            "401/401 [==============================] - 206s 514ms/step - loss: 0.1832 - accuracy: 0.9422 - val_loss: 0.5299 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 5/7\n",
            "401/401 [==============================] - 206s 513ms/step - loss: 0.1719 - accuracy: 0.9452 - val_loss: 0.1585 - val_accuracy: 0.9508 - lr: 0.0010\n",
            "401/401 [==============================] - 210s 524ms/step - loss: 0.1572 - accuracy: 0.9487 - val_loss: 0.2641 - val_accuracy: 0.9311 - lr: 0.0010\n",
            "Epoch 7/7\n",
            "401/401 [==============================] - 208s 518ms/step - loss: 0.2153 - accuracy: 0.9328 - val_loss: 11595.6719 - val_accuracy: 0.1106 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "# Define directories and constants\n",
        "source_dir = \"/content/drive/MyDrive/PlantVillage/Tomato\"\n",
        "train_dir = \"tomato/train\"\n",
        "valid_dir = \"tomato/valid\"\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "numEPOCHS = 7  # You can increase the number of epochs\n",
        "\n",
        "# Data Augmentation\n",
        "training_aug = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "testing_aug = ImageDataGenerator(rescale=1./255.0)\n",
        "\n",
        "# Load and preprocess data\n",
        "training_data = training_aug.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "testing_data = testing_aug.flow_from_directory(\n",
        "    valid_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Define and compile the model\n",
        "base_model = InceptionV3(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(CLASS_NUMS, activation='softmax')\n",
        "])\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "def lr_scheduler(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.0001\n",
        "\n",
        "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Training with early stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    training_data,\n",
        "    validation_data=testing_data,\n",
        "    epochs=numEPOCHS,\n",
        "    steps_per_epoch=len(training_data),\n",
        "    validation_steps=len(testing_data),\n",
        "    callbacks=[early_stopping, lr_schedule]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtEH69b-51Oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4651b129-0396-4b23-cd7d-4346bf119a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save(\"tomato_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9znM6Nxk54hC"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import warnings\n",
        "\n",
        "#lodaing the trained model\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "model = keras.models.load_model('tomato_model.h5')\n",
        "\n",
        "#converting model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "#saving tflite model\n",
        "with open('tomato.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "#creating interpreter for our model\n",
        "interpreter = tf.lite.Interpreter(model_path='tomato.tflite')\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmUDvgleI-vA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33fe5074-68a9-4dbe-f87c-1df77a9c5fbc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f6f76ee9-e37b-484d-ba73-cfcff8fcfc27\", \"tomato_model.h5\", 275203472)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"tomato_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSutkk69Ol5F"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#files.download(\"tomato.tflite\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}